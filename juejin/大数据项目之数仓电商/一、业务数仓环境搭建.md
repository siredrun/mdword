# 一、2.0对比1.0的改动

| 改动       | 1.0                | 2.0                        |
| ---------- | ------------------ | -------------------------- |
| 业务数仓   | 7张表              | 24张表                     |
| 数仓分层   | 4层                | 5层，多了DWT(主题明细层)层 |
| 建模方式   |                    | 更规范                     |
| 数据可视化 | springboot+echarts | superset                   |
| 集群监控   |                    | zabbix                     |
| 元数据     |                    | atlas                      |
| 权限管理   |                    | ranger                     |

# 二、电商业务介绍

## 1.术语介绍

sku: 一款商品中的具体某一个型号的产品

spu:一款商品

 uv: user views 用户浏览总量

 pv: page views 页面浏览总量



## 2.电商关键业务表

| 表名                             | 同步方式   | 字段名       | 字段描述                           |
| -------------------------------- | ---------- | ------------ | ---------------------------------- |
| order_info(订单表)               | 新增和变化 | order_status | 订单状态(会被修改)                 |
|                                  |            | create_time  | 创建时间                           |
|                                  |            | operate_time | 操作时间(最后一次修改订单的时间)   |
| order_detail(订单详情表)         | 增量       | create_time  | 创建时间                           |
|                                  |            | order_id     | 订单号可以和order_info.id关联      |
| sku_info(sku商品表)              | 全量       | create_time  | 创建时间                           |
| user_info(用户表)                | 新增和变化 | create_time  | 创建时间                           |
|                                  |            | operate_time | 操作时间(最后一次用户信息的时间)   |
| payment_info(支付流水表)         | 增量       | payment_time | 支付时间                           |
| base_category1(商品一级分类表)   | 全量       |              |                                    |
| base_category2(商品二级分类表)   | 全量       |              |                                    |
| base_category3(商品三级分类表)   | 全量       |              |                                    |
| base_province（省份表）          | 全量导一次 |              |                                    |
| base_region(地区表)              | 全量导一次 |              |                                    |
| base_trademark（品牌表）         | 全量       |              |                                    |
| order_status_log(订单状态表)     | 增量       | operate_time | 操作时间                           |
| spu_info(SPU商品表)              | 全量       |              |                                    |
| comment_info(商品评论表)         | 增量       | create_time  | 创建时间                           |
| order_refund_info（退单表）      | 增量       | create_time  | 创建时间                           |
| cart_info(加购表)                | (特殊)全量 | create_time  | 创建时间                           |
|                                  |            | operate_time | 操作时间(最后一次修改购物车的时间) |
| favor_info（商品收藏表）         | (特殊)全量 | create_time  | 创建时间                           |
|                                  |            | cancel_time  | 取消收藏的最后一次时间             |
| coupon_use（优惠券领用表）       | 增量和变化 | get_time     | 领券时间                           |
|                                  |            | using_time   | 使用时间                           |
|                                  |            | used_time    | 支付时间                           |
| coupon_info（优惠券表）          | 全量       | create_time  | 创建时间                           |
| activity_info（活动表）          | 全量       | create_time  | 创建时间                           |
| activity_order（活动订单关联表） | 增量       | create_time  | 创建日期                           |
| activity_rule（优惠规则表）      | 全量       |              |                                    |
| base_dic（编码字典表）           | 全量       | create_time  | 创建日期                           |
|                                  |            | operate_time | 操作时间(最后一次修改的时间)       |
| date_info（时间表）              | 全量导一次 |              |                                    |
| holiday_info（假期表）           | 全量导一次 |              |                                    |
| holiday_year（假期年表）         | 全量导一次 |              |                                    |



## 3.业务表的同步方式

### 3.1 同步的周期

​		每天同步一次！每天将同步的数据在hive中创建一个分区！

​		一般是次日凌晨0:30(保证用户行为数据已经采集到hdfs)开始同步前一天的数据！



### 3.2 同步的策略

原则： 数据的同步策略只取决于数据量！

​			数据量小或修改频率低的表一般可以进行全量同步(省事)！

​			数据量大或修改频率高的表一般使用增量同步！

增量同步： select * from 表名 where create_time='同步的数据日期'

全量同步： select * from 表名

新增和变化同步：  select * from 表名 where create_time='同步的数据日期' or operate_time='同步的数据日期'



### 3.3 数据的保存周期

​		数仓中的数据需要保留半年的回溯周期！



## 4.数仓中表的分类

事实表： 记录某个发生的事实。一般在记录事实时会参考3W原则，对事实进行描述。记录who ，where, when,do



维度表： 用来描述事实，或描述事实中的某一部分！



事务型事实表：  特点是一旦事实发生，不会改变！表中的记录，一般只会新增！

周期型事实表： 记录事实，只记录这个事实在某个时间周期内最终的状态！重视结果！

累积型快照事实表： 记录事实，记录整个事实在某个时间周期内的累积的变化状态！重视过程！



## 5.数仓中表的分层

ODS层：  原始数据层，将采集的数据原封不动导入！

​					分区表！按照日期进行分区！

DWD层：数据明细层，将ODS层的数据，进行ETL后，展开明细！

​					分区表！按照日期进行分区！

DWS层： 数据服务层，将DWD层数据，每天轻度聚合！每天一个分区！

​					分区表！按照日期进行分区！

DWT层： 数据主题层，围绕某个具体要统计的主题，例如日活，订单，用户等，一张总表，记录了从第一天截至今日的所有的围绕此主题的汇总数据！

​					不是分区表！一张普通表！

ADS层： 数据应用层。可以从DWS层或DWT层取需要的数据！

​					不是分区表！一张普通表！



## 6.数仓中每层表的建模

ODS： 特点是保持原始数据的原貌，不作修改！

​			原始数据怎么建模，ODS就怎么建模！

​			举例：  用户行为数据特征是一条记录就是一行！

​						ODS层表(line string)

​							业务数据，参考Sqoop导入的数据类型进行建模！



DWD层：特点从ODS层，将数据进行ETL（清洗），轻度聚合，再展开明细！

​				 ①在展开明细时，对部分维度表进行降维操作！

​				例如：将商品一二三级分类表，sku商品表，spu商品表，商品品牌表合并汇总为一张维度表！

​				②对事实表，参考星型模型的建模策略，按照**选择业务过程→声明粒度→确认维度→确认事实**思路进行建模

​				选择业务过程： 选择感兴趣的事实表

​				声明粒度： 选择最细的粒度！可以由最细的粒度通过聚合的方式得到粗粒度！

​				确认维度： 根据3w原则确认维度，挑选自己感兴趣的维度

​				确认事实： 挑选感兴趣的度量字段，一般是从事实表中选取！

​				 

DWS层： 根据业务需求进行分主题建模！一般是建宽表！

DWT层：  根据业务需求进行分主题建模！一般是建宽表！

ADS层：  根据业务需求进行建模！

# 三、安装Hive2.3

## 1.安装hive

①解压tar包

②修改/etc/profile中HIVE_HOME=新hive的家目录

③配置hive-site.xml

④拷贝mysql的驱动到HVIE_HOME/lib



## 2.使用Hive

先启动hive metastore的服务！

```
hive --service metastore &
```



## 3.使用JDBC方式连接Hive

配置core-site.xml

```xml
<property>
<name>hadoop.proxyuser.atguigu.hosts</name>
<value>*</value>
</property>
<property>
<name>hadoop.proxyuser.atguigu.groups</name>
<value>*</value>
</property>
```

配置hdfs-site.xml

```xml
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
```

分发之后重启hdfs!

开启hiveserver2服务

```
hiveserver2
```

# 四、ODS层

## 1.数据的准备

### 1.1 造log数据

例如造05-06,05-07，xxx

①先将集群时间调整到以上日期中最早的一天 dt.sh 最早 的日期

②启动采集通道 onekeyboot.sh start

③造数据 lg 200 300

④去hdfs上查看



⑤将集群的时间，往后调整，此时采集通道不需要重启！  dt.sh xxx

​	之后重复③，④



## 1.2 造db数据

①修改application.properties，重点改数据库连接的参数

```
mock.date=造数据的日期
#第一次，mock.clear=1，之后改为0
mock.clear=1
```

②执行造数据的程序

```
java -jar gmall-mock-db-2020-03-16-SNAPSHOT.jar
```

③去数据库中查看

④执行sqoop的导入脚本

```
mysql_to_hdfs.sh xxx xxxx
```

业务数据，必须造一天，导一天！

mysql_to_hdfs.sh   参数1  参数2

​		参数1：  frist(第一次导数据) |  all(之后每天导) | 表名

​		参数2： 日期，如果缺省，默认选择当前日期的前一天



⑤重复①-④

## 2.向ods层导入数据

### 2.1 导入log数据到ods层

先建表！

```
hdfs_to_ods_log.sh 日期
```

### 2.2 导入db数据到ods层

先建表！

```
hdfs_to_ods_db.sh  first|all 日期
```



## 3.向dwd层导入数据

先建表！

### 2.1 导入log数据到dwd层

导入启动日志数据

```
ods_to_dwd_log.sh 日期
```

创建两个函数

```
create function base_analizer as 'com.atguigu.udf.MyUDF'
create function flat_analizer as 'com.atguigu.udtf.MyUDTF'
```

将事件日志，拆散到base表中

```
ods_to_dwd_base_log.sh 日期
```

从base表导入各个事件表

```
ods_to_dwd_event_log.sh 日期
```

