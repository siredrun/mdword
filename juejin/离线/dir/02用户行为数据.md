# 用户行为数据概述

用户在使用产品时，记录用户和产品交互行为的数据，称为用户行为数据。例如点赞，点击，浏览，收藏等。

分类：当前应用的数据分为启动日志和事件日志。
1.事件日志
描述： 用户使用APP时，记录各种交互行为的数据！
格式：时间戳(上传的时间戳)|｛"ap":"产品来源","cm":{设备的公共字段},"et":[{事件},{},{}]｝

2.启动日志的格式
启动日志： 用户打开应用，此时记录一些信息。启动日志对于分析日活，月活等数据非常有用的。
格式：{"en":"start",...}

## 埋点数据基本格式

l 公共字段：基本所有安卓手机都包含的字段。

l 业务字段：埋点上报的字段，有具体的业务类型。

下面就是一个示例，表示业务字段的上传。

```
{
"ap":"xxxxx",//项目数据来源 app pc
"cm": {  //公共字段
		"mid": "",  // (String) 设备唯一标识
        "uid": "",  // (String) 用户标识
        "vc": "1",  // (String) versionCode，程序版本号
        "vn": "1.0",  // (String) versionName，程序版本名
        "l": "zh",  // (String) language系统语言
        "sr": "",  // (String) 渠道号，应用从哪个渠道来的。
        "os": "7.1.1",  // (String) Android系统版本
        "ar": "CN",  // (String) area区域
        "md": "BBB100-1",  // (String) model手机型号
        "ba": "blackberry",  // (String) brand手机品牌
        "sv": "V2.2.1",  // (String) sdkVersion
        "g": "",  // (String) gmail
        "hw": "1620x1080",  // (String) heightXwidth，屏幕宽高
        "t": "1506047606608",  // (String) 客户端日志产生时的时间
        "nw": "WIFI",  // (String) 网络模式
        "ln": 0,  // (double) lng经度
        "la": 0  // (double) lat 纬度
    },
"et":  [  //事件
            {
                "ett": "1506047605364",  //客户端事件产生时间
                "en": "display",  //事件名称
                "kv": {  //事件结果，以key-value形式自行定义
                    "goodsid": "236",
                    "action": "1",
                    "extend1": "1",
"place": "2",
"category": "75"
                }
            }
        ]
}
```

示例日志（服务器时间戳 | 日志）：

```
1540934156385|{
    "ap": "gmall", 
    "cm": {
        "uid": "1234", 
        "vc": "2", 
        "vn": "1.0", 
        "la": "EN", 
        "sr": "", 
        "os": "7.1.1", 
        "ar": "CN", 
        "md": "BBB100-1", 
        "ba": "blackberry", 
        "sv": "V2.2.1", 
        "g": "abc@gmail.com", 
        "hw": "1620x1080", 
        "t": "1506047606608", 
        "nw": "WIFI", 
        "ln": 0
    }, 
        "et": [
            {
                "ett": "1506047605364",  //客户端事件产生时间
                "en": "display",  //事件名称
                "kv": {  //事件结果，以key-value形式自行定义
                    "goodsid": "236",
                    "action": "1",
                    "extend1": "1",
"place": "2",
"category": "75"
                }
            },{
		        "ett": "1552352626835",
		        "en": "active_background",
		        "kv": {
			         "active_source": "1"
		        }
	        }
        ]
    }
}
```

下面是各个埋点日志格式。其中商品点击属于信息流的范畴。

## 事件日志-商品列表页(loading)

事件名称：loading

| 标签         | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| action       | 动作：开始加载=1，加载成功=2，加载失败=3                     |
| loading_time | 加载时长：计算下拉开始到接口返回数据的时间，（开始加载报0，加载成功或加载失败才上报时间） |
| loading_way  | 加载类型：1-读取缓存，2-从接口拉新数据   （加载成功才上报加载类型） |
| extend1      | 扩展字段 Extend1                                             |
| extend2      | 扩展字段 Extend2                                             |
| type         | 加载类型：自动加载=1，用户下拽加载=2，底部加载=3（底部条触发点击底部提示条/点击返回顶部加载） |
| type1        | 加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败） |

## 事件日志-商品点击(display)

事件标签：display

| 标签     | 含义                                                         |
| -------- | ------------------------------------------------------------ |
| action   | 动作：曝光商品（正常曝光的商品）=1，点击商品（购买流量的商品，如商品图片有广告二字的商品）=2， |
| goodsid  | 商品ID（服务端下发的ID）                                     |
| place    | 顺序（第几条商品，第一条为0，第二条为1，如此类推）           |
| extend1  | 曝光类型：1 - 首次曝光 2-重复曝光                            |
| category | 分类ID（服务端定义的分类ID）                                 |

## 事件日志-商品详情页(newsdetail)

事件标签：newsdetail

| 标签          | 含义                                                         |
| ------------- | ------------------------------------------------------------ |
| entry         | 页面入口来源：应用首页=1、push=2、详情页相关推荐=3           |
| action        | 动作：开始加载=1，加载成功=2（pv），加载失败=3, 退出页面=4   |
| goodsid       | 商品ID（服务端下发的ID）                                     |
| show_style    | 商品样式：0、无图、1、一张大图、2、两张图、3、三张小图、4、一张小图、5、一张大图两张小图 |
| news_staytime | 页面停留时长：从商品开始加载时开始计算，到用户关闭页面所用的时间。若中途用跳转到其它页面了，则暂停计时，待回到详情页时恢复计时。或中途划出的时间超过10分钟，则本次计时作废，不上报本次数据。如未加载成功退出，则报空。 |
| loading_time  | 加载时长：计算页面开始加载到接口返回数据的时间 （开始加载报0，加载成功或加载失败才上报时间） |
| type1         | 加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败） |
| category      | 分类ID（服务端定义的分类ID）                                 |

## 事件日志-广告(ad)

事件名称：ad

| 标签         | 含义                                       |
| ------------ | ------------------------------------------ |
| entry        | 入口：商品列表页=1 应用首页=2 商品详情页=3 |
| action       | 动作： 广告展示=1 广告点击=2               |
| contentType  | Type: 1 商品 2 营销活动                    |
| displayMills | 展示时长 毫秒数                            |
| itemId       | 商品id                                     |
| activityId   | 营销活动id                                 |

## 事件日志-消息通知(notification)

事件标签：notification

| 标签    | 含义                                                         |
| ------- | ------------------------------------------------------------ |
| action  | 动作：通知产生=1，通知弹出=2，通知点击=3，常驻通知展示（不重复上报，一天之内只报一次）=4 |
| type    | 通知id：预警通知=1，天气预报（早=2，晚=3），常驻=4           |
| ap_time | 客户端弹出时间                                               |
| content | 备用字段                                                     |

## 事件日志-用户后台活跃(active_background)

事件标签: active_background

| 标签          | 含义                                        |
| ------------- | ------------------------------------------- |
| active_source | 1=upgrade,2=download(下载),3=plugin_upgrade |

## 事件日志-评论（comment）

描述：评论表

| **序号** | **字段名称** | **字段描述**                              | **字段类型** | **长度** | **允许空** | **缺省值** |
| -------- | ------------ | ----------------------------------------- | ------------ | -------- | ---------- | ---------- |
| 1        | comment_id   | 评论表                                    | int          | 10,0     |            |            |
| 2        | userid       | 用户id                                    | int          | 10,0     | √          | 0          |
| 3        | p_comment_id | 父级评论id(为0则是一级评论,不为0则是回复) | int          | 10,0     | √          |            |
| 4        | content      | 评论内容                                  | string       | 1000     | √          |            |
| 5        | addtime      | 创建时间                                  | string       |          | √          |            |
| 6        | other_id     | 评论的相关id                              | int          | 10,0     | √          |            |
| 7        | praise_count | 点赞数量                                  | int          | 10,0     | √          | 0          |
| 8        | reply_count  | 回复数量                                  | int          | 10,0     | √          | 0          |

 

## 事件日志-收藏（favorites）

描述：收藏

| **序号** | **字段名称** | **字段描述** | **字段类型** | **长度** | **允许空** | **缺省值** |
| -------- | ------------ | ------------ | ------------ | -------- | ---------- | ---------- |
| 1        | id           | 主键         | int          | 10,0     |            |            |
| 2        | course_id    | 商品id       | int          | 10,0     | √          | 0          |
| 3        | userid       | 用户ID       | int          | 10,0     | √          | 0          |
| 4        | add_time     | 创建时间     | string       |          | √          |            |

## 事件日志-点赞（praise）

描述：所有的点赞表

| **序号** | **字段名称** | **字段描述**                                            | **字段类型** | **长度** | **允许空** | **缺省值** |
| -------- | ------------ | ------------------------------------------------------- | ------------ | -------- | ---------- | ---------- |
| 1        | id           | 主键id                                                  | int          | 10,0     |            |            |
| 2        | userid       | 用户id                                                  | int          | 10,0     | √          |            |
| 3        | target_id    | 点赞的对象id                                            | int          | 10,0     | √          |            |
| 4        | type         | 点赞类型 1问答点赞 2问答评论点赞 3 文章点赞数4 评论点赞 | int          | 10,0     | √          |            |
| 5        | add_time     | 添加时间                                                | string       |          | √          |            |

 

## 事件日志-错误日志

| errorBrief  | 错误摘要 |
| ----------- | -------- |
| errorDetail | 错误详情 |

## 启动日志数据

事件标签: start

| 标签         | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| entry        | 入口： push=1，widget=2，icon=3，notification=4, lockscreen_widget =5 |
| open_ad_type | 开屏广告类型: 开屏原生广告=1, 开屏插屏广告=2                 |
| action       | 状态：成功=1 失败=2                                          |
| loading_time | 加载时长：计算下拉开始到接口返回数据的时间，（开始加载报0，加载成功或加载失败才上报时间） |
| detail       | 失败码（没有则上报空）                                       |
| extend1      | 失败的message（没有则上报空）                                |
| en           | 日志类型start                                                |

```
{
    "action":"1",
    "ar":"MX",
    "ba":"HTC",
    "detail":"",
    "en":"start",
    "entry":"2",
    "extend1":"",
    "g":"43R2SEQX@gmail.com",
    "hw":"640*960",
    "l":"en",
    "la":"20.4",
    "ln":"-99.3",
    "loading_time":"2",
    "md":"HTC-2",
    "mid":"995",
    "nw":"4G",
    "open_ad_type":"2",
    "os":"8.1.2",
    "sr":"B",
    "sv":"V2.0.6",
    "t":"1561472502444",
    "uid":"995",
    "vc":"10",
    "vn":"1.3.4"
}
```

# 用户行为数据采集

## 日志生成

把log-collector项目打包生成的log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar（带依赖的jar包）上传到linux。

```
lg #日志生成脚本
xcall ls /tmp/logs  # 在hadoop102和hadoop103下的/tmp/logs/里面生成app-*.log文件
要执行的命令是:ls /tmp/logs
-----------------------hadoop102---------------------
hadoop102 ls /tmp/logs
app-2020-06-29.log
-----------------------hadoop103---------------------
hadoop103 ls /tmp/logs
app-2020-06-29.log
-----------------------hadoop104---------------------
hadoop104 ls /tmp/logs
ls: cannot access /tmp/logs: No such file or directory

# 通过修改系统时间，模拟生成不同日期的数据
dt '2019-12-15'
------------同步hadoop102时间--------------
Sun Dec 15 00:00:00 CST 2019
------------同步hadoop103时间--------------
Sun Dec 15 00:00:00 CST 2019
------------同步hadoop104时间--------------
Sun Dec 15 00:00:00 CST 2019

lg #日志生成
xcall ls /tmp/logs 
要执行的命令是:ls /tmp/logs
-----------------------hadoop102---------------------
hadoop102 ls /tmp/logs
app-2019-12-15.log
app-2020-06-30.log
-----------------------hadoop103---------------------
hadoop103 ls /tmp/logs
app-2019-12-15.log
app-2020-06-30.log
-----------------------hadoop104---------------------
hadoop104 ls /tmp/logs
ls: cannot access /tmp/logs: No such file or directory

ct # 更新集群时间为现在时刻
-----------hadoop102---------------
13 Jul 19:02:27 ntpdate[43022]: step time server 120.25.115.20 offset 4734041.379608 sec
-----------hadoop103---------------
13 Jul 19:02:34 ntpdate[25666]: step time server 120.25.115.20 offset 4734041.516882 sec
-----------hadoop104---------------
13 Jul 19:02:40 ntpdate[27046]: step time server 120.25.115.20 offset 4734041.652027 sec

```

\>命令解释

当执行一个命令时，如果此条命令有输出，可以使用 > 符号，讲输出定向到某个文件中。此时标注输出就不向屏幕输出了。

如：

```shell
locate javac.1
/usr/java/jdk1.8.0_181-cloudera/man/ja_JP.UTF-8/man1/javac.1
/usr/java/jdk1.8.0_181-cloudera/man/man1/javac.1
locate javac.1 > a.log 
cat a.log 
/usr/java/jdk1.8.0_181-cloudera/man/ja_JP.UTF-8/man1/javac.1
/usr/java/jdk1.8.0_181-cloudera/man/man1/javac.1
```

Linux中的IO设备
在linux中，有三个常用的IO设备
0： 代表标注输入。类似Java中的System.in.scan()，接受用户的输入。
1:   代表标注输出。类似Java中的System.out.print()，接受程序的标注输出（正常输出，默认的输入）。
2:   代表错误输出。类似Java中的System.err.print()，接受程序报错时输出的信息。		
/dev/null : 俗称黑洞，如果输出中消息不希望使用，可以定向输出到此设备。		
格式：命令 > 文件：  执行命令，将命令的标注输出定向到文件中！
命令 > 文件 等价于  命令 1> 文件。如：pwd 1 > a.log 等同于 pwd > a.log 。

pwd 2 >&c.log等价于pwd 1 > c.log 2 >&c.log ： 将pwd的错误消息定向到c.log，没有报错，消息还是使用标注输出在控制台输出！
pwd 1> c.log 2> c.log 等价于 pwd 1> e.log 2>&1  ： pwd程序的标注输出和错误输出都输出到c.log。

```shell
pwdw 2 >&a.log
 cat a.log 
-bash: pwdw: command not found
```

解释：

```
> /dev/null 正常输出到黑洞
2>&1 错误信息变为正常输出
& 后台执行
```

## 日志采集

![](https://user-gold-cdn.xitu.io/2020/7/1/1730965577e0024e?w=670&h=308&f=png&s=16508)

集群规划

| 服务名称        | 子服务 | 服务器  hadoop102 | 服务器  hadoop103 | 服务器  hadoop104 |
| --------------- | ------ | ----------------- | ----------------- | ----------------- |
| Flume(采集日志) | Flume  | √                 | √                 |                   |

开始

```
# 添加两个主题topic_start、topic_event，分区副本都是1。
kafka-topics.sh  --zookeeper hadoop102:2181/kafka --create --partitions 1 --replication-factor 1 --topic topic_start
kafka-topics.sh --bootstrap-server hadoop102:9092 --create --partitions 1 --replication-factor 1  --topic topic_event
kafka-topics.sh --bootstrap-server hadoop102:9092 --list
topic_event
topic_start

# 把项目flume-interceptor打包生成的flume-interceptor-1.0-SNAPSHOT.jar放在$FL_HOME/lib下
xsync flume-interceptor-1.0-SNAPSHOT.jar
xcall ls $FL_HOME/lib|grep flume-interceptor-1.0-SNAPSHOT.jar 
flume-interceptor-1.0-SNAPSHOT.jar
flume-interceptor-1.0-SNAPSHOT.jar
flume-interceptor-1.0-SNAPSHOT.jar

xcall ls $FL_HOME/conf # 保证hadoop102和hadoop103的$FL_HOME/myagents下有Flume Agent配置文件f1.conf
xcall ls $FL_HOME/conf/file-flume-kafka.conf # 保证hadoop102/3的$FL_HOME/conf下有Flume Agent配置文件file-flume-kafka.conf
要执行的命令是:ls /opt/module/fl/conf/file-flume-kafka.conf
-----------------------ls /opt/module/fl/conf/file-flume-kafka.conf---------------------
hadoop102 ls /opt/module/fl/conf/file-flume-kafka.conf
/opt/module/fl/conf/file-flume-kafka.conf
-----------------------ls /opt/module/fl/conf/file-flume-kafka.conf---------------------
hadoop103 ls /opt/module/fl/conf/file-flume-kafka.conf
/opt/module/fl/conf/file-flume-kafka.conf
-----------------------ls /opt/module/fl/conf/file-flume-kafka.conf---------------------
hadoop104 ls /opt/module/fl/conf/file-flume-kafka.conf
/opt/module/fl/conf/file-flume-kafka.conf

# 测试采集
xcall rm -rf /tmp/logs/*
lg #分别在hadoop102和hadoop103下/tmp/logs产生数据
xcall ls /tmp/logs # 查看hadoop102和hadoop103有无生成app*.log日志
f1 start # 开始采集hadoop102和hadoop103上的数据，必须保证zk、kf的启动。
 --------启动 hadoop102 采集flume-------
 --------启动 hadoop103 采集flume-------

# 起两个消费端消费topic_start和topic_event
kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic topic_start
kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic topic_event

# 使用kafka tool2查看两个主题topic_start和topic_event的“total number of messages”信息总数在收集前后有无增加2000条。关于执行日志请查看/opt/module/fl/f1，根据f1采集脚本里的“...EBUG,console > /opt/module/fl/f1 2>&1 &”，有错误请根据这个来解决。
```

## 采集总结

1）Source
Taildir Source相比Exec Source、Spooling Directory Source的优势
TailDir Source：断点续传、多目录。Flume1.6以前需要自己自定义Source记录每次读取文件位置，实现断点续传。
Exec Source可以实时搜集数据，但是在Flume不运行或者Shell命令出错的情况下，数据将会丢失。
Spooling Directory Source监控目录，不支持断点续传。
batchSize大小如何设置？答：Event 1K左右时，500-1000合适（默认为100）
2）Channel
采用Kafka Channel，省去了Sink，提高了效率。KafkaChannel数据存储在Kafka里面，所以数据是存储在磁盘中。
注意在Flume1.7以前，Kafka Channel很少有人使用，因为发现parseAsFlumeEvent这个配置起不了作用。也就是无论parseAsFlumeEvent配置为true还是false，都会转为Flume Event。这样的话，造成的结果是，会始终都把Flume的headers中的信息混合着内容一起写入Kafka的消息中，只需要把内容写入即可。

## 日志消费

消费Kafka数据Flume

![](https://user-gold-cdn.xitu.io/2020/7/1/1730966c6f056e9d?w=662&h=312&f=png&s=16761)

集群规划

| 服务名称           | 子服务 | 服务器  hadoop102 | 服务器  hadoop103 | 服务器  hadoop104 |
| ------------------ | ------ | ----------------- | ----------------- | ----------------- |
| Flume（消费Kafka） | Flume  |                   |                   | √                 |

开始

```
xcall ls $FL_HOME/conf/ | grep kafka-flume-hdfs # 保证集群所有节点都有f2.conf日志消费
kafka-flume-hdfs.conf
kafka-flume-hdfs.conf
kafka-flume-hdfs.conf

#确保kafka tool2查看两个主题topic_start和topic_event的“total number of messages”信息总数大于0，有数据，没有日志就lg生成数据，f1 start开始采集。
f2 start #启动日志消费，有错误查看$FL_HOME/f2
dt '2020-05-20' # 修改日期
xcall date \$F
要执行的命令是:date $F
-----------------------date $F---------------------
hadoop102 date $F
Wed May 20 00:22:47 CST 2020
-----------------------date $F---------------------
hadoop103 date $F
Wed May 20 00:22:47 CST 2020
-----------------------date $F---------------------
hadoop104 date $F
Wed May 20 00:22:47 CST 2020

lg
xcall ls /tmp/logs | grep 2020-05-20
app-2020-05-20.log
app-2020-05-20.log

f1 start

# 查看是否在hdfs上生成数据
hadoop fs -ls /origin_data/gmall/log/topic_start
Found 2 items
drwxr-xr-x   - admin supergroup          0 2020-05-20 00:14 /origin_data/gmall/log/topic_start/2020-05-20
drwxr-xr-x   - admin supergroup          0 2020-07-16 01:19 /origin_data/gmall/log/topic_start/2020-07-16

hadoop fs -ls /origin_data/gmall/log/topic_event
Found 2 items
drwxr-xr-x   - admin supergroup          0 2020-05-20 00:14 /origin_data/gmall/log/topic_event/2020-05-20
drwxr-xr-x   - admin supergroup          0 2020-07-16 01:19 /origin_data/gmall/log/topic_event/2020-07-16

hadoop fs -ls /origin_data/gmall/log/topic_start/2020-07-16
Found 2 items
-rw-r--r--   1 admin supergroup     485253 2020-07-16 00:58 /origin_data/gmall/log/topic_start/2020-07-16/logstart-.1594832309337.lzo
-rw-r--r--   1 admin supergroup      99205 2020-07-16 01:19 /origin_data/gmall/log/topic_start/2020-07-16/logstart-.1594833540393.lzo

hadoop fs -ls /origin_data/gmall/log/topic_event/2020-05-20
Found 2 items
-rw-r--r--   1 admin supergroup     324511 2020-05-20 00:12 /origin_data/gmall/log/topic_event/2020-05-20/logevent-.1589904762382.lzo
-rw-r--r--   1 admin supergroup     149849 2020-05-20 00:14 /origin_data/gmall/log/topic_event/2020-05-20/logevent-.1589904833606.lzo

ct #更改时间到现在时刻
-----------hadoop102---------------
17 Jul 20:06:36 ntpdate[45313]: step time server 120.25.115.20 offset 4935084.086897 sec
-----------hadoop103---------------
17 Jul 20:06:42 ntpdate[44935]: step time server 120.25.115.20 offset 4935084.186697 sec
-----------hadoop104---------------
17 Jul 20:06:49 ntpdate[50528]: step time server 120.25.115.20 offset 4935084.360948 sec

如果hdfs里面没有生成数据，可能是之前的数据已经消费完毕，偏移量已到最后。两种解决方案：1.把偏移量设置为0最开始的位置；2.重新采集新的日志数据添加到kafka主题。
1.通过kafka-consumer-groups.sh --bootstrap-server hadoop102:9092 --describe --group CG_Start # 查看消费者消费偏移量，如果OFFSET的值不为0，请设置为最初偏移量。OFFSET记录kafka消费的指针，比如消费者有100条数据，但是OFFSET为99，就表示已经消费完了，kafka不会往hdfs里面存储数据。可以通过设置消费者offset的为0来解决。注意：这种方式我暂时不会，待解决！
2.重新采集
1g # 生产数据
f1 start # 日志采集脚本启动
f2 start # 日志消费脚本启动
```
