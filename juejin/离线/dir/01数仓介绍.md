# 数仓基础

## 概念

数据仓库(DataWarehouse)是为企业所有决策制定过程，促供所有系统数据支持的战略集合。通过对数据仓库中数据的分析可以帮助企业，改进业务程、控制成本、提高产品质量等。数据仓库，并不是数据的最终目的地，而是为数据最终的目的地做好准。这些准条包括对数据的：清洗转义，分类，重组：合并，拆分，统计等等。

![](https://user-gold-cdn.xitu.io/2020/6/28/172f8d626d2d6145?w=494&h=308&f=png&s=13939)



## 项目需求

一、项目需求

1、用户行为数据采集平台搭建

2、业务数据采集平台搭建

3、数据仓库维度建模

4、分析，用户、流量、会员、商品、销售、地区、活动等电商核心主题，统计的报表指标近100个。完全对比中型公司

5、采用即席查询工具，随时进行指标分析

6、对集群性能进行监控，发生异常需要报警

7、元数据管理

8、质量监控

二、思考题

1、项目技术选型?

2、框架版本选型(Apache、CDH、HDP)？

3、服务器使用物理机还是云主机?

4、确认集群规模?(假设每台服务器8T硬盘)

## 技术选型

考虑因数：数据量大小、业务需求、行业内经验、技术成熟度、开发维护成本、总成本预算。

数据采集传输：Flume，Kafka， Sqoop， Logstash， DataX，

数据存储：MySql， HDFS， HBase，Redis，MongoDB

数据计算：Hive， Tez，Spark，Flink， Storm

数据查询：Presto，Druid，Impala，Kylin

数据可视化：Echarts、Superset、Tableau、QuickBI、DataV

任务调度：Azkaban、Oozie

集群监控：Zabbix

元数据管理：Atlas

## 系统数据流程

Web/业务服务器业务交互数据：业务流程中产生的登录、订单、用户、App(Spring boo)业务日志数据(后瑞埋点数据)Ng in x商品、支付等相关的数据，通常存储在DB中，包括业务Mysql、Oracle等。

埋点用户行为数据：用户在使用产品过程中.与客户编产品交互SparkS tH base视化过程中产生的数据.比如页面浏览、点击、停留、评论、点赞、reaming收藏等。

![](https://user-gold-cdn.xitu.io/2020/7/12/1733ed1299d9eb1a?w=899&h=438&f=png&s=49716)

## 框架版本

(1) Apache：运维麻烦，组件间兼容性需要自己调研。(一般大厂使用，技术实力雄厚，有专业的运维人员)

(2) CDH：国内使用最多的版本， 但CM不开源， 但其实对中、小公司使用来说没有影响(建议使用)，今年开始收费，一个节点1万美金

(3) HDP；开源， 可以进行二次开发， 但是没有CDH稳定， 国内使用较少

## 具体版本型号

注意：下面所有产品的版本除了

(1) Apache框架版本产品版本

| 产品                                   | 版本           |
| -------------------------------------- | -------------- |
| <span style='color:red;'>hadoop</span> | 2.7.2/3.1.3    |
| <span style='color:red;'>flume</span>  | 1.7.0/1.9.0    |
| kafka                                  | 0.11.0.2/2.4.1 |
| <span style='color:red;'>hive</span>   | 2.3/3.1        |
| sqoop                                  | 1.4.6          |
| zookeeper                              | 3.4.10/3.5.7   |
| java                                   | 1.8            |
| azkaban                                | 2.5.0          |
| presto                                 | 0.189          |
| mysql                                  | 5.7            |

(2) CDH框架版本5.12.1/5.6/6.2.0

| 产品                                   | 版本  |
| -------------------------------------- | ----- |
| <span style='color:red;'>hadoop</span> | 2.6.0 |
| <span style='color:red;'>flume</span>  | 1.6.0 |
| <span style='color:red;'>spark</span>  | 1.6.0 |
| <span style='color:red;'>hive</span>   | 1.1.0 |
| sqoop                                  | 1.4.6 |
| zookeeper                              | 3.4.5 |
| oozie                                  | 4.1.0 |
| impala                                 | 2.9.0 |

注意事项：框架选型尽量不要选择最新的框架，选择最新框架半年前左右的稳定版。

## 服务器选型

选择物理机还是云主机?

1)机器成本考虑：物理机：以128G内存， 20核物理CPU， 40线程，8THDD和2TSSD硬盘， 戴尔品牌单台报价4W出头，需考虑托管服务器费用。一般物理机寿命5年左右；云主机，以阿里云为例，差不多相同配置，每年5W。

2)运维成本考虑：物理机：需要有专业的运维人员；云主机：很多运维工作都由阿里云完成，运维相对较轻松。

3)企业选择：金融有钱公司且和阿里没有直接冲突的公司选择阿里云；中小公司、为了融资上市，选择阿里云，拉到融资后买物理机；有长期打算，资金比较足，选择物理机。

## 集群资源规划

1）如何确认集群规模？(假设：每台服务器8T磁盘，128G内存)

(1)每天日活跃用户100万，每人一天平均100条：100万*100条=10000万条*

(2)每条日志1K左右，每天1亿条：100000000/1024/1024=约100G

(3)半年内不扩容服务器来算：100G\*180天=约18T

(4)保存3副本：18T\*3=54T

(5)预留20%~30%Buf=54T/0.7=77T

(6)算到：约8T\*10台服务器

2）如果考虑数仓分层？数据需要压缩？需要重新再计算。

3）测试集群服务器规划

| 服务名称           | 子服务                | 服务器  hadoop102 | 服务器  hadoop103 | 服务器  hadoop104 |
| ------------------ | --------------------- | ----------------- | ----------------- | ----------------- |
| HDFS               | NameNode              | √                 |                   |                   |
|                    | DataNode              | √                 | √                 | √                 |
|                    | SecondaryNameNode     |                   |                   | √                 |
| Yarn               | NodeManager           | √                 | √                 | √                 |
|                    | Resourcemanager       |                   | √                 |                   |
| Zookeeper          | Zookeeper Server      | √                 | √                 | √                 |
| Flume(采集日志)    | Flume                 | √                 | √                 |                   |
| Kafka              | Kafka                 | √                 | √                 | √                 |
| Flume（消费Kafka） | Flume                 |                   |                   | √                 |
| Hive               | Hive                  | √                 |                   |                   |
| MySQL              | MySQL                 | √                 |                   |                   |
| Sqoop              | Sqoop                 | √                 |                   |                   |
| Presto             | Coordinator           | √                 |                   |                   |
|                    | Worker                |                   | √                 | √                 |
| Azkaban            | AzkabanWebServer      | √                 |                   |                   |
|                    | AzkabanExecutorServer | √                 |                   |                   |
| Druid              | Druid                 | √                 | √                 | √                 |
| Kylin              |                       | √                 |                   |                   |
| Hbase              | HMaster               | √                 |                   |                   |
|                    | HRegionServer         | √                 | √                 | √                 |
| Superset           |                       | √                 |                   |                   |
| Atlas              |                       | √                 |                   |                   |
| Solr               | Jar                   | √                 |                   |                   |
| 服务数总计         |                       | 19                | 9                 | 9                 |

## 范式理论

定义：范式可以理解为设计一张数据表的表结构，符合的标准级别。 规范和要求
优点：关系型数据库设计时，遵照一定的规范要求，目的在于降低数据的冗余性。
降低数据冗余性目的：
（1）十几年前，磁盘很贵，为了减少磁盘存储。
（2）以前没有分布式系统，都是单机，只能增加磁盘，磁盘个数也是有限的
（3）一次修改，需要修改多个表，很难保证数据一致性
缺点：获取数据时，需要通过Join拼接出最后的数据。
分类：第一范式(1NF)、第二范式(2NF)、第三范式(3NF)、巴斯-科德范式(BCNF)、第四范式(4NF)、第五范式(5NF)。 

**三大范式（3NF）**
1、第一范式（1NF）：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；

2、第二范式（2NF）：满足1NF后，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分；

3、第三范式（3NF）：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关（表中的每一列只能依赖于主键）；

## 关系建模和维度建模

当今的数据处理大致可以分成两大类：联机事务处理OLTP（on-line transaction processing）、联机分析处理OLAP（On-Line Analytical Processing）。OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。二者的主要区别对比如下表所示。

| **对比属性** | **OLTP**                   | **OLAP**                   |
| ------------ | -------------------------- | -------------------------- |
| **读特性**   | 每次查询只返回少量记录     | 对大量记录进行汇总         |
| **写特性**   | 随机、低延时写入用户的输入 | 批量导入                   |
| **使用场景** | 用户，Java EE项目          | 内部分析师，为决策提供支持 |
| **数据表征** | 最新数据状态               | 随时间变化的历史状态       |
| **数据规模** | GB                         | TB到PB                     |

**关系建模**

![](https://user-gold-cdn.xitu.io/2020/7/19/17365ce764ca85d0?w=706&h=382&f=png&s=80833)

关系模型如图所示，严格遵循第三范式（3NF），从图中可以看出，较为松散、零碎，物理表数量多，而数据冗余程度低。由于数据分布于众多的表中，这些数据可以更为灵活地被应用，功能性较强。关系模型主要应用与OLTP系统中，为了保证数据的一致性以及避免冗余，所以大部分业务系统的表都是遵循第三范式的。关系模型虽然冗余少，但是在大规模数据，跨表分析统计查询过程中，会造成多表关联，这会大大降低执行效率。

**维度建模**

维度模型如下图所示，主要应用于OLAP系统中，通常以某一个事实表为中心进行表的组织，主要面向业务，特征是可能存在数据的冗余，但是能方便的得到数据。关系模型虽然冗余少，但是在大规模数据，跨表分析统计查询过程中，会造成多表关联，这会大大降低执行效率。所以通常我们采用维度模型建模，把相关各种表整理成两种：事实表和维度表两种。

![](https://user-gold-cdn.xitu.io/2020/7/19/17365cff1007d65b?w=648&h=508&f=png&s=73358)

在维度建模的基础上又分为三种模型：星型模型、雪花模型、星座模型。

**星型模型**

雪花模型与星型模型的区别主要在于维度的层级，标准的星型模型维度只有一层，而雪花模型可能会涉及多级。

![](https://user-gold-cdn.xitu.io/2020/7/19/17365d6235ab7125?w=634&h=384&f=png&s=189905)

**雪花模型**

雪花模型，比较靠近3NF，但是无法完全遵守，因为遵循3NF的性能成本太高。

![](https://user-gold-cdn.xitu.io/2020/7/19/17365d621307b495?w=629&h=375&f=png&s=212838)

**星座模型**

星座模型与前两种情况的区别是事实表的数量，星座模型是基于多个事实表。基本上是很多数据仓库的常态，因为很多数据仓库都是多个事实表的。所以星座不星座只反映是否有多个事实表，他们之间是否共享一些维度表。所以星座模型并不和前两个模型冲突。

![](https://user-gold-cdn.xitu.io/2020/7/19/17365d6256a26e74?w=616&h=391&f=png&s=229785)

**模型选择**

首先就是星座不星座这个只跟数据和需求有关系，跟设计没关系，不用选择。星型还是雪花，取决于性能优先，还是灵活更优先。目前实际企业开发中，不会绝对选择一种，根据情况灵活组合，甚至并存(一层维度和多层维度都保存)。但是整体来看，更倾向于维度更少的星型模型。尤其是Hadoop体系， 减少Join就是减少Shuffle， 性能差距很大。(关系型数据可以依靠强大的主键索引)。

## 维度表和事实表（重点）

**维度表**

维度表：一般是对事实的描述信息。每一张维表对应现实世界中的一个对象或者概念。  例如：用户、商品、日期、地区等。

**特征**：

维表的范围很宽（具有多个属性、列比较多）

跟事实表相比，行数相对较小：通常< 10万条

内容相对固定：编码表

时间维度表：

| 日期ID     | day of week | day of year | 季度 | 节假日 |
| ---------- | ----------- | ----------- | ---- | ------ |
| 2020-01-01 | 2           | 1           | 1    | 元旦   |
| 2020-01-02 | 3           | 2           | 1    | 无     |
| 2020-01-03 | 4           | 3           | 1    | 无     |
| 2020-01-04 | 5           | 4           | 1    | 无     |
| 2020-01-05 | 6           | 5           | 1    | 无     |

**事实表**

事实表中的每行数据代表一个业务事件（下单、支付、退款、评价等）。“事实”这个术语表示的是业务事件的度量值（可统计次数、个数、金额等），例如，订单事件中的下单金额。

每一个事实表的行包括：具有可加性的数值型的度量值、与维表相连接的外键、通常具有两个和两个以上的外键、外键之间表示维表之间多对多的关系。

**特征**：

行数非常的大

内容相对的窄：列数较少

经常发生变化，每天会新增加很多。

**1）事务型事实表**

以每个事务或事件为单位，例如一个销售订单记录，一笔支付记录等，作为事实表里的一行数据。一旦事务被提交，事实表数据被插入，数据就不再进行更改，其更新方式为增量更新。 

**2）周期型快照事实表**

周期型快照事实表中不会保留所有数据，只保留固定时间间隔的数据，例如每天或者每月的销售额，或每月的账户余额等。

**3）累积型快照事实表**

累计快照事实表用于跟踪业务事实的变化。例如，数据仓库中可能需要累积或者存储订单从下订单开始，到订单商品被打包、运输、和签收的各个业务阶段的时间点数据来跟踪订单声明周期的进展情况。当这个业务过程进行时，事实表的记录也要不断更新。

| 订单id | **用户id** | **下单时间** | **打包时间** | **发货时间** | **签收时间** | **订单金额** |
| ------ | ---------- | ------------ | ------------ | ------------ | ------------ | ------------ |
|        |            | 3-8          | 3-8          | 3-9          | 3-10         |              |

**总结**

事实表： 记录某个发生的事实。一般在记录事实时会参考3W原则，对事实进行描述。记录who，where，when。

维度表： 用来描述事实，或描述事实中的某一部分！

事务型事实表：  特点是一旦事实发生，不会改变！表中的记录，一般只会新增！

周期型事实表： 记录事实，只记录这个事实在某个时间周期内最终的状态！重视结果！

累积型快照事实表： 记录事实，记录整个事实在某个时间周期内的累积的变化状态！重视过程！

## 数仓分层

**原始数据层ODS(Operation Data Store)**：存放原始数据，直接加载原始日志、数据数据保持原貌不做处理。

**服务数据层DWD(data warehouse detail)**：对ODS层数据进行清洗(去除空值，脏数据，超过极限范围的数据)、维度退化、脱敏等

**明细数据层DWS(data warehouse service)**：以DWD为基础，按天进行轻度汇总。

**数据主题层DWT(data warehouse Topic)**：以DWS为基础，按主题进行汇总。

**数据应用层ADS(Application Data Store)**：为各种统计报表提供数据。

**分层目的**

1)**把复杂问题简单化**，将复杂的任务分解成多层来完成，每一层只处理简单的任务，方便定位问题；

2)**减少重复开发**，规范数据分层通过的中间层数据，能够减少极大的重复计算，增加一次计算结果的复用件；

3)**隔离原始数据**，不论是数据的异常还是数据的敏感性，使真实数据与统计数据解耦；

**数据集市与数据仓库概念**

数据集市(DataMarket) ， 现在市面上的公司和书籍都对数据集市有不同的概念数据集市则是一种微型的数据仓库，它通常有更少的数据，更少的主题区域，以及更少的历史数据，因此是部门级的，一般只能为某个局部范内的管理人员服务。。数据仓库是企业级的，能为整个企业各个部门的运行提供决策支持手段。

![](https://user-gold-cdn.xitu.io/2020/7/2/1730d434871f468e?w=1101&h=532&f=png&s=187623)

**命名规范**

1.**数仓表**

ODS层命名为ods_表名

DWD层命名为dwd_dim/fact_表名

DWS层命名为dws_表名

DWT层命名为dwt_购物车

ADS层命名为ads_表名

临时表命名为xxx_tmp

用户行为表，以log为后缀。

**2.数仓脚本**

数据源_to_目标_db/log.sh

用户行为脚本以log为后缀；业务数据脚本以db为后缀。

**总结**

ODS层：  原始数据层，将采集的数据原封不动导入。分区表，按照日期进行分区。

DWD层：数据明细层，将ODS层的数据，进行ETL后，展开明细。分区表，按照日期进行分区。

DWS层： 数据服务层，将DWD层数据，每天轻度聚合！每天一个分区，分区表，按照日期进行分区。

DWT层： 数据主题层，围绕某个具体要统计的主题，例如日活，订单，用户等，一张总表，记录了从第一天截至今日的所有的围绕此主题的汇总数据。非分区表，一张普通表。

ADS层： 数据应用层。可以从DWS层或DWT层取需要的数据。非分区表，一张普通表。

## 数仓建模（重点）

### ODS层

（1）保持数据原貌不做任何修改，作用：备份数据。

（2）数据采用压缩，减少磁盘存储空间（例如：原始数据100G，可压缩到10G左右）。

（3）创建分区表，防止后续的全表扫描。

### DWD层

DWD层需构建维度模型，一般采用星型模型，呈现状态为星座模型。

维度建模一般按照以下四个步骤：选择业务过程→声明粒度→确认维度→确认事实

（1）**选择业务过程**

在业务系统中挑选一个业务线，如下单业务，支付业务，退款业务，物流业务，一条业务线对应一张事实表。

（2）**声明粒度**

数据粒度指数据仓库的数据中保存数据的细化程度或综合程度的级别。声明粒度意味着精确定义事实表中的一行数据表示什么，应该尽可能选择最小粒度，以此来应各种各样的需求。

典型的粒度声明如下：

订单中，每个商品项作为下单事实表中的一行，粒度为每次下单

每周的订单次数作为一行，粒度就是每周下单。

每月的订单次数作为一行，粒度就是每月下单

（3）**确定维度**

维度的主要作用是描述业务，主要表示的是“who，where，when”等3w信息。

（4）**确认事实**

此处的“事实”一词，指业务中的**度量值**，如订单金额、下单次数等。

在DWD层，以业务过程为建模驱动，基于每个具体业务过程的特点，构建**最细粒度**的明细层事实表。事实表可做适当的宽表化处理。

![](https://imgkr.cn-bj.ufileos.com/a9a299e7-13d2-46e4-8c11-d54a8712f7c7.png)

举例：选择业务(支付)=》声明粒度（每天、每100条，按时间数量等）=》确认维度（表）时间、地区、商品、优惠券、活动等维度表=》确认事实：如日活率、每日优惠券使用率、每日某商品购买率等。

|                | **时间** | **用户** | **地区** | **商品** | **优惠券** | **活动** | **编码** | **度量值** |
| -------------- | -------- | -------- | -------- | -------- | ---------- | -------- | -------- | ---------- |
| **订单**       | √        | √        | √        |          |            | √        |          | 件数/金额  |
| **订单详情**   | √        |          | √        | √        |            |          |          | 件数/金额  |
| **支付**       | √        |          | √        |          |            |          |          | 金额       |
| **加购**       | √        | √        |          | √        |            |          |          | 件数/金额  |
| **收藏**       | √        | √        |          | √        |            |          |          | 个数       |
| **评价**       | √        | √        |          | √        |            |          |          | 个数       |
| **退款**       | √        | √        |          | √        |            |          |          | 件数/金额  |
| **优惠券领用** | √        | √        |          |          | √          |          |          | 个数       |

至此，数仓的维度建模已经完毕，DWS、DWT和ADS和维度建模已经没有关系了。DWS和DWT都是建宽表，宽表都是按照主题去建。主题相当于观察问题的角度。对应着维度表。

### DWS层

统计各个主题对象的当天行为，服务于DWT层的主题宽表，以及一些业务明细数据，应对特殊需求（例如，购买行为，统计商品复购率）。如每日设备/会员/商品行为、每日地区/活动统计

### DWT层

以分析的**主题对象**为建模驱动，基于上层的应用和产品的指标需求，构建主题对象的全量宽表。如用户/设备/商品主题、地区/营销活动主题

### ADS层

对电商系统各大主题指标分别进行分析。

### 总结

ODS层： 特点是保持原始数据的原貌，不作修改！原始数据怎么建模，ODS就怎么建模。（保持原样、压缩、分区）

举例： 用户行为数据特征是一条记录就是一行，ODS层表(line string)；业务数据，参考Sqoop导入的数据类型进行建模。

DWD层：特点从ODS层，将数据进行ETL（清洗），轻度聚合，再展开明细。

①在展开明细时，对部分维度表进行降维操作。如：将商品一二三级分类表，sku商品表，spu商品表，商品品牌表合并汇总为一张维度表。例如：将商品一二三级分类表，sku商品表，spu商品表，商品品牌表合并汇总为一张维度表！

②对事实表，参考星型模型的建模策略，按照**选择业务过程→声明粒度→确认维度→确认事实**思路进行建模

选择业务过程： 选择感兴趣的事实表。
声明粒度： 选择最细的粒度！可以由最细的粒度通过聚合的方式得到粗粒度。
选择维度： 根据3w原则确认维度，挑选自己感兴趣的维度。
确认事实： 挑选感兴趣的度量字段，一般是从事实表中选取。

DWS层： 根据业务需求进行分主题建模！一般是建宽表！

DWT层：  根据业务需求进行分主题建模！一般是建宽表！

ADS层：  根据业务需求进行建模！	